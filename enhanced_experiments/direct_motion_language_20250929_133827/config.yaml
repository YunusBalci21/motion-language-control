algo: ppo
baselines:
  clip_based_reward: true
  clip_encoding_time: 15
  pixel_rendering_time: 7
  pretrained_locomotion: false
  random_policy: false
  vision_based_reward: false
environment:
  alternatives:
  - HalfCheetah-v4
  - Ant-v4
  - Walker2d-v4
  id: Humanoid-v4
  max_episode_steps: 1000
  max_steps: 1000
  name: HumanoidStable-v4
  num_envs: 8
  render_mode: null
evaluation:
  benchmark_against_clip: true
  compute_similarity_metrics: true
  cross_evaluation: true
  eval_deterministic: true
  n_eval_episodes: 10
  record_videos: true
  reward_threshold_success: 100.0
  save_episode_videos: true
  similarity_threshold_excellent: 0.8
  similarity_threshold_good: 0.6
  track_computation_times: true
experiment:
  authors:
  - Yunus Emre Balci
  description: Enhanced motion-language control using direct MotionGPT integration
  institution: SDU
  name: direct_motion_language_learning
  version: '3.0'
experimental:
  adaptive_curriculum: false
  augmentation_noise_std: 0.01
  curriculum_success_threshold: 0.75
  stability_bonus_weight: 0.3
  use_audio_instructions: false
  use_instruction_specific_rewards: true
  use_motion_augmentation: false
  use_progress_bonus: true
  use_visual_features: false
hardware:
  compile_model: false
  device: auto
  gradient_accumulation_steps: 1
  max_memory_usage_gb: 8.0
  mixed_precision: false
hierarchical:
  discover_skills: false
  high_level_freq: 1
  low_level_freq: 10
  n_discovered_skills: 16
  skill_embedding_dim: 64
  use_hierarchical_structure: true
instructions:
  advanced:
  - walk in a circle
  - walk forward then turn left
  - walk backward then turn around
  - jump up and down
  - wave your hand while walking
  - crouch down low
  - walk sideways to the left
  - walk sideways to the right
  - run in a circle
  - march in place
  - walk forward for 10 steps then stop
  - turn around and walk back
  - walk forward while staying upright
  - move forward with smooth motions
  - walk forward and keep your head up
  basic:
  - walk forward
  - walk backward
  - turn left
  - turn right
  - stop moving
  - walk stably
  - walk but not fall
  - move forward slowly
  - keep your balance
  expert:
  - walk forward slowly then speed up
  - turn left then walk backward
  - jump three times then walk forward
  - wave both hands while walking forward
  - walk in a figure eight pattern
  - crouch walk forward
  - walk forward then jump then continue walking
  - clean the table then organize items
  - pick up object then place it carefully
  - reach forward then wipe surface thoroughly
  intermediate:
  - walk forward slowly
  - walk forward quickly
  - run forward
  - turn left while walking
  - turn right while walking
  - walk in place
  - walk forward without falling
  - move steadily forward
  - walk and maintain balance
  - walk smoothly forward
  - take careful steps forward
  - walk forward with good posture
  manipulation:
  - clean the table
  - wipe the surface
  - pick up that object
  - place it over there
  - organize the items
  - reach for the object
  - grasp it carefully
  - move it slowly
  - clean thoroughly
  - tidy up the area
  - reach forward carefully
  - pick up object slowly
  - clean the surface smoothly
  - organize items carefully
  - move object gently
  - wipe table thoroughly
  - grasp object securely
  - place object down carefully
  stability_focused:
  - walk stably without falling
  - maintain balance while moving
  - walk with good balance
  - move forward but stay upright
  - walk carefully without stumbling
  - take stable steps forward
  - walk with good posture and balance
  - move steadily and don't fall
  - walk forward and keep your balance
  - move smoothly without losing balance
logging:
  log_level: INFO
  save_model_every_n_steps: 10000
  tensorboard_log: ./logs/
  track_metrics:
  - motion_language_similarity
  - language_reward
  - original_env_reward
  - episode_length
  - computation_time
  - motion_variance
  wandb_project: null
motion_gpt:
  checkpoint_path: null
  codebook_size: 512
  config_path: null
  language_model: t5-small
  latent_dim: 256
  max_sequence_length: 196
  motion_dim: 263
  motion_history_length: 20
  motion_normalization: true
  reward_smoothing: 0.9
  success_threshold: 0.6
  temporal_aggregation: weighted_recent
ppo:
  batch_size: 64
  clip_range: 0.2
  clip_ratio: 0.2
  ent_coef: 0.0
  epochs: 10
  gae_lambda: 0.95
  gamma: 0.99
  lam: 0.95
  learning_rate: 0.0003
  lr: 0.0003
  max_grad_norm: 0.5
  minibatches: 32
  n_epochs: 10
  n_steps: 2048
  norm_adv: true
  steps_per_update: 8192
  vf_coef: 0.5
reproducibility:
  deterministic_training: false
  generate_performance_plots: true
  save_hyperparameters: true
  save_model_architecture: true
  save_random_state: true
  save_training_curves: true
  seed: 42
training:
  checkpoint_freq: 5000
  eval_freq: 10000
  language_reward_weights:
  - 0.3
  - 0.4
  - 0.5
  - 0.6
  - 0.7
  - 0.8
  - 0.9
  n_parallel_envs: 1
  total_timesteps_per_instruction: 10000
  use_multiprocessing: false
